{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Example\n",
    "\n",
    "This notebook demonstrates the usage of our custom Bagging implementation for both classification and regression tasks, including visualizations to illustrate its effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from bagging import BaggingClassifier, BaggingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate a single Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "# Train and evaluate Bagging Classifier\n",
    "bc = BaggingClassifier(n_estimators=10, max_samples=0.8)\n",
    "bc.fit(X_train, y_train)\n",
    "bc_pred = bc.predict(X_test)\n",
    "bc_accuracy = accuracy_score(y_test, bc_pred)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Bagging Classifier Accuracy: {bc_accuracy:.4f}\")\n",
    "\n",
    "# Visualize decision boundaries\n",
    "def plot_decision_boundary(clf, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(dt, X, y, f'Decision Tree (Accuracy: {dt_accuracy:.4f})')\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(bc, X, y, f'Bagging Classifier (Accuracy: {bc_accuracy:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=1, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate a single Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_pred)\n",
    "\n",
    "# Train and evaluate Bagging Regressor\n",
    "br = BaggingRegressor(n_estimators=10, max_samples=0.8)\n",
    "br.fit(X_train, y_train)\n",
    "br_pred = br.predict(X_test)\n",
    "br_mse = mean_squared_error(y_test, br_pred)\n",
    "\n",
    "print(f\"Decision Tree MSE: {dt_mse:.4f}\")\n",
    "print(f\"Bagging Regressor MSE: {br_mse:.4f}\")\n",
    "\n",
    "# Visualize regression results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(X_test, y_test, alpha=0.5)\n",
    "plt.plot(X_test, dt_pred, color='r', label='Decision Tree')\n",
    "plt.title(f'Decision Tree (MSE: {dt_mse:.4f})')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(X_test, y_test, alpha=0.5)\n",
    "plt.plot(X_test, br_pred, color='g', label='Bagging Regressor')\n",
    "plt.title(f'Bagging Regressor (MSE: {br_mse:.4f})')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the effectiveness of our custom Bagging implementation for both classification and regression tasks. The visualizations illustrate how Bagging can create smoother decision boundaries in classification and more robust predictions in regression compared to a single decision tree. This often leads to improved performance and reduced overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}